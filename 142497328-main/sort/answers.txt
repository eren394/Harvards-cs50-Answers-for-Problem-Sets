Program 1: Selection Sort Explanation: Program 1 took approximately the same amount of time to sort random50000.txt, sorted50000.txt, and reversed50000.txt. This is characteristic of Selection Sort (O(n2)), as it must iterate through the remaining unsorted elements to find the minimum value regardless of the initial order of the list. It does not have an "early exit" for sorted data.

Program 2: Merge Sort Explanation: Program 2 was significantly faster than the other two programs when handling the 50,000-line files, finishing in a fraction of a second. This indicates a logarithmic time complexity (O(nlogn)). Unlike the O(n2) algorithms, Merge Sort's divide-and-conquer approach allows it to scale much more efficiently as the input size increases.

Program 3: Bubble Sort Explanation: Program 3 showed a massive disparity in timing between the file types. It sorted sorted50000.txt nearly instantaneously (O(n)), but performed very slowly on reversed50000.txt and random50000.txt (O(n2)). This behavior is unique to Bubble Sort, which can stop early if it completes a pass with zero swaps, but must perform many swaps if the data is out of order.
